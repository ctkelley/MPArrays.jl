<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · MultiPrecisionArrays.jl</title><meta name="title" content="Home · MultiPrecisionArrays.jl"/><meta property="og:title" content="Home · MultiPrecisionArrays.jl"/><meta property="twitter:title" content="Home · MultiPrecisionArrays.jl"/><meta name="description" content="Documentation for MultiPrecisionArrays.jl."/><meta property="og:description" content="Documentation for MultiPrecisionArrays.jl."/><meta property="twitter:description" content="Documentation for MultiPrecisionArrays.jl."/><script data-outdated-warner src="assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="search_index.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href>MultiPrecisionArrays.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Home</a><ul class="internal"><li><a class="tocitem" href="#What-is-iterative-refinement."><span>What is iterative refinement.</span></a></li><li><a class="tocitem" href="#Integral-Equations-Example"><span>Integral Equations Example</span></a></li></ul></li><li><span class="tocitem">GMRES-IR</span><ul><li><a class="tocitem" href="Half_1/">Half Precision and GMRES-IR</a></li></ul></li><li><span class="tocitem">More than you want to know</span><ul><li><a class="tocitem" href="Details/Termination/">Terminating the while loop</a></li><li><a class="tocitem" href="Details/Interprecision_1/">Interprecision Transfers: Part I</a></li></ul></li><li><span class="tocitem">MPArray Constructors</span><ul><li><a class="tocitem" href="functions/MPArray/">MPArray: constructor</a></li></ul></li><li><span class="tocitem">Factorizations</span><ul><li><a class="tocitem" href="functions/hlu!/">hlu!: Get LU to perform reasonably well for Float16</a></li><li><a class="tocitem" href="functions/mplu!/">mplu!: Simple MPArray factorization</a></li></ul></li><li><span class="tocitem">Solvers</span><ul><li><a class="tocitem" href="functions/mpgeslir/">mpgeslir: IR solver</a></li><li><a class="tocitem" href="functions/mpgmir/">mpgmir: GMRES-IR solver</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Home</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Home</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/ctkelley/MultiPrecisionArrays.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/ctkelley/MultiPrecisionArrays.jl/blob/main/docs/src/index.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="MultiPrecisionArrays.jl-v0.0.6"><a class="docs-heading-anchor" href="#MultiPrecisionArrays.jl-v0.0.6">MultiPrecisionArrays.jl v0.0.6</a><a id="MultiPrecisionArrays.jl-v0.0.6-1"></a><a class="docs-heading-anchor-permalink" href="#MultiPrecisionArrays.jl-v0.0.6" title="Permalink"></a></h1><p><a href="https://ctk.math.ncsu.edu">C. T. Kelley</a></p><p><a href="https://github.com/ctkelley/MultiPrecisionArrays.jl">MultiPrecisionArrays.jl</a> is a package for iterative refinement. </p><p>This package provides data structures and solvers for several variants of iterative refinement. It will become much more useful when half precision (aka <code>Float16</code>) is fully supported in LAPACK/BLAS. For now, it&#39;s only general-purpose application is classical iterative refinement with double precision equations and single precision factorizations.</p><p>The half precision stuff is good for those of us doing research in this field. Half precision performance has progressed to the point where you can actually get things done. On an Apple M2-Pro, a half precision LU only costs 3–5 times what a double precision LU costs. This may be as good as it gets unless someone wants to duplicate the LAPACK implementation and get the benefits from blocking, recursion, and clever cache management.</p><p>We use a hack-job LU factorization for half precision. Look at the source for <strong>hlu!.jl</strong>.</p><h2 id="What-is-iterative-refinement."><a class="docs-heading-anchor" href="#What-is-iterative-refinement.">What is iterative refinement.</a><a id="What-is-iterative-refinement.-1"></a><a class="docs-heading-anchor-permalink" href="#What-is-iterative-refinement." title="Permalink"></a></h2><p>The idea is to solve <span>$Ax=b$</span> in high precision using a factorization in lower precision. </p><p><strong>IR(A, b)</strong></p><ul><li>Initialize: <span>$x = 0$</span>,  <span>$r = b$</span></li><li>Factor <span>$A = LU$</span> in a lower precision</li><li>While <span>$\| r \|$</span> is too large<ul><li>Compute the defect <span>$d = (LU)^{-1} r$</span></li><li>Correct the solution <span>$x = x + d$</span></li><li>Update the residual <span>$r = b - Ax$</span></li></ul></li><li>end</li></ul><p>In Julia, a code to do this would solve the linear system <span>$A x = b$</span> in double precision by using a factorization in a lower precision, say single, within a residual correction iteration. This means that one would need to allocate storage for a copy of <span>$A$</span> is the lower precision and factor that copy. </p><p>Then one has to determine what the line <span>$d = (LU)^{-1} r$</span> means. Do you cast <span>$r$</span> into the lower precision before the solve or not? <strong>MultiPrecisionArrays.jl</strong> provides data structures and solvers to manage this. </p><p>Here&#39;s a simple Julia function for IR that</p><pre><code class="nohighlight hljs">&quot;&quot;&quot;
IR(A,b)
Simple minded iterative refinement
Solve Ax=b
&quot;&quot;&quot;
function IR(A, b)
    x = zeros(length(b))
    r = copy(b)
    tol = 100.0 * eps(Float64)
    #
    # Allocate a single precision copy of A and factor in place
    #
    A32 = Float32.(A)
    AF = lu!(A32)
    #
    # Give IR at most ten iterations, which it should not need
    # in this case
    #
    itcount = 0
    # The while loop will get more attention later.
    while (norm(r) &gt; tol * norm(b)) &amp;&amp; (itcount &lt; 10)
        #
        # Store r and d = AF\r in the same place.
        #
        ldiv!(AF, r)
        x .+= r
        r .= b - A * x
        itcount += 1
    end
    return x
end</code></pre><p>The <strong>MPArray</strong> structure contains both <span>$A$</span>, the low precision copy, and a vector for the residual.  This lets you allocate the data in advance and reuse the structure for other right hand sides without rebuilding (or refactoring!) the low precision copy. </p><p>As written in the function, the defect uses <code>ldiv!</code> to compute <code>AF\r</code>. This means that the two triangular factors are stored in single precision and interprecision transfers are done with each step in the factorization. While that <code>on the fly</code> interprecision  transfer is an option, and is needed in many situations, the default is to downcast <span>$r$</span> to low precision, do the solve entirely in low precision, and the upcast the result. The code for that looks like</p><pre><code class="nohighlight hljs">normr=norm(r)
ds=Float32.(r)/normr
ldiv!(AF, ds)
r .= Float64.(ds)*normr</code></pre><p>The scaling by <code>1.0/normr</code> avoids underflow, which is most important when the low precision is <code>Float16</code>. We will discuss interprecision  transfer costs later.</p><h2 id="Integral-Equations-Example"><a class="docs-heading-anchor" href="#Integral-Equations-Example">Integral Equations Example</a><a id="Integral-Equations-Example-1"></a><a class="docs-heading-anchor-permalink" href="#Integral-Equations-Example" title="Permalink"></a></h2><p>The submodule <strong>MultiPrecisionArrays.Examples</strong> has an example which we will  use for most of the documentation. The function <code>Gmat(N)</code> returns the trapeziod rule discretization of the Greens operator  for <span>$-d^2/dx^2$</span> on <span>$[0,1]$</span> with homogeneous Dirichlet boundary conditions.</p><p class="math-container">\[G u(x) = \int_0^1 g(x,y) u(y) \, dy \]</p><p>where</p><p class="math-container">\[g(x,y) = 
    \left\{\begin{array}{c}
        y (1-x) ; \ x &gt; y\\
        x (1-y) ; \ x \le y
    \end{array}\right.\]</p><p>The eigenvalues of <span>$G$</span> are <span>$1/(n^2 \pi^2)$</span> for <span>$n = 1, 2, \dots$</span>.</p><p>The code for this is in the <strong>/src/Examples</strong> directory.  The file is <strong>Gmat.jl</strong>.</p><p>In the example we will build a matrix <span>$A = I - \alpha G$</span>. In the examples we will use <span>$\alpha=1.0$</span>, a very well conditioned case, and <span>$\alpha=800.0$</span> This latter case is very near singularity.</p><p>We will solve a linear system with both double precision <span>$LU$</span> and an MPArray and compare execution time and the quality of the results. The problem setup is pretty simple</p><pre><code class="nohighlight hljs">julia&gt; using MultiPrecisionArrays

julia&gt; using BenchmarkTools

julia&gt; using MultiPrecisionArrays.Examples

julia&gt; N=4096; G=Gmat(N); A=I - G; x=ones(N); b=A*x;

julia&gt; @belapsed lu!(AC) setup=(AC=copy($A))
1.43148e-01</code></pre><p>At this point we have timed <code>lu!</code>. The next step is to construct an MPArray and factor the low precision matrix. We use the constructor <code>MPArray</code> to store <span>$A$</span>, the low precision copy and the residual. The we apply the function <code>mplu!</code> to factor the low precision copy in place.</p><pre><code class="nohighlight hljs">julia&gt; MPA=MPArray(A);

julia&gt; @belapsed mplu!(MPAC) setup=(MPAC=deepcopy($MPA))
8.02158e-02</code></pre><p>So the single precision factorization is roughly half the cost of the double precision one. Now for the solves. Both <code>lu!</code> and <code>mplu!</code> produce a factorization object and <code>\</code> works with both. You have to be a bit careful because MPA and A share storage. So I will use <code>lu</code> instead of <code>lu!</code> when factoring <span>$A$</span>.</p><pre><code class="nohighlight hljs">julia&gt; AF=lu(A); xf = AF\b;

julia&gt; MPAF=mplu!(MPA); xmp=MPAF\b;

julia&gt; println(norm(xf-x,Inf),&quot;  &quot;,norm(xmp-x,Inf))
7.41629e-14  8.88178e-16</code></pre><p>You can see that the solutions are equally good.</p></article><nav class="docs-footer"><a class="docs-footer-nextpage" href="Half_1/">Half Precision and GMRES-IR »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="auto">Automatic (OS)</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.0.1 on <span class="colophon-date" title="Tuesday 26 September 2023 17:47">Tuesday 26 September 2023</span>. Using Julia version 1.9.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
